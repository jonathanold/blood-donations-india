{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27429614",
   "metadata": {
    "papermill": {
     "duration": 0.004081,
     "end_time": "2024-04-11T06:34:35.839171",
     "exception": false,
     "start_time": "2024-04-11T06:34:35.835090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Code to extraxct blood bank info for Odisha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec8368a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T06:34:35.846989Z",
     "iopub.status.busy": "2024-04-11T06:34:35.846607Z",
     "iopub.status.idle": "2024-04-11T06:34:39.495589Z",
     "shell.execute_reply": "2024-04-11T06:34:39.494452Z"
    },
    "papermill": {
     "duration": 3.659779,
     "end_time": "2024-04-11T06:34:39.502399",
     "exception": false,
     "start_time": "2024-04-11T06:34:35.842620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>400 Bad Request</title>\n",
      "</head><body>\n",
      "<h1>Bad Request</h1>\n",
      "<p>Your browser sent a request that this server could not understand.<br />\n",
      "</p>\n",
      "</body></html>\n",
      "\n",
      "Ready to go !\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "initiate = 0\n",
    "\n",
    "\n",
    "# Headers from your browser's developer tools\n",
    "headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"en-DE,en-US;q=0.9,en;q=0.8,de;q=0.7\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Content-Length\": \"0\",\n",
    "    \"Cookie\": \"PHPSESSID=iht8rj2tfjjuoaokh23iblpnn3\",\n",
    "    \"Host\": \"ebloodbankodisha.nic.in\",\n",
    "    \"Origin\": \"https://ebloodbankodisha.nic.in\",\n",
    "    \"Referer\": \"https://ebloodbankodisha.nic.in/\",\n",
    "    \"Sec-Ch-Ua\": '\"Not A(Brand\";v=\"99\", \"Google Chrome\";v=\"121\", \"Chromium\";v=\"121\"',\n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "    \"Sec-Ch-Ua-Platform\": '\"macOS\"',\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "# Test on one request\n",
    "base_url = \"https://eblood.odisha.gov.in/Web/ajaxAvailabilityBloodStockFront/distid:1/bbid:84\"\n",
    "response = requests.post(base_url, headers=headers, verify=False)\n",
    "print(response.status_code)\n",
    "print(response.text)\n",
    "\n",
    "# Base URL: Set up for loop\n",
    "base_url = \"https://ebloodbankodisha.nic.in/Web/ajaxAvailabilityBloodStockFront/distid:{}/bbid:{}\"\n",
    "\n",
    "print('Ready to go !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a88a6",
   "metadata": {
    "papermill": {
     "duration": 0.00469,
     "end_time": "2024-04-11T06:34:39.517763",
     "exception": false,
     "start_time": "2024-04-11T06:34:39.513073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loop\n",
    "\n",
    "Loop over districts and blood banks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819c177b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T06:34:39.525316Z",
     "iopub.status.busy": "2024-04-11T06:34:39.524317Z",
     "iopub.status.idle": "2024-04-11T06:34:39.538457Z",
     "shell.execute_reply": "2024-04-11T06:34:39.537901Z"
    },
    "papermill": {
     "duration": 0.020132,
     "end_time": "2024-04-11T06:34:39.539972",
     "exception": false,
     "start_time": "2024-04-11T06:34:39.519840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if initiate==1:\n",
    "        \n",
    "    # Data storage for the entire dataset\n",
    "    full_dataset = []\n",
    "    districtn = \"Test\"\n",
    "    district = \"Test\"\n",
    "    hospital_name = \"Test\"\n",
    "\n",
    "    hospital_namen = \"Test\"\n",
    "\n",
    "    # Iterate over all possible combinations of distid and bbid\n",
    "    for distid in range(1, 32):\n",
    "        for bbid in range(1, 121):\n",
    "            url = base_url.format(distid, bbid)\n",
    "\n",
    "            # Assuming it's a POST request; adjust if necessary\n",
    "            response = requests.post(url, headers=headers, verify=False)\n",
    "\n",
    "            # Check if the request was successful (status code 200)\n",
    "            if response.status_code == 200:\n",
    "\n",
    "                # Parse the HTML content using BeautifulSoup\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                # Extract relevant information from the HTML\n",
    "                data_vector = []\n",
    "                rows = soup.find_all('tr')\n",
    "                for row in rows:\n",
    "                    # Extract individual cells from the row\n",
    "                    cells = row.find_all('td')\n",
    "\n",
    "                    # Extract and organize data into a vector\n",
    "                    district = cells[0].text.strip()\n",
    "                    hospital_name = cells[1].text.strip()\n",
    "                    blood_units = [cell.text.strip() for cell in cells[2:10]]\n",
    "                    last_updated = cells[-2].text.strip()\n",
    "                    \n",
    "                    # Create a vector with the extracted data\n",
    "                    row_vector = [distid, bbid, district, hospital_name] + blood_units + [last_updated]\n",
    "                    \n",
    "                if district==districtn and hospital_name==hospital_namen:\n",
    "                    pass\n",
    "                else:\n",
    "                    # Append the vector to the data list\n",
    "                    data_vector.append(row_vector)\n",
    "                    \n",
    "                    # Append the data vector to the full dataset\n",
    "                    print(f\"Got data for distid={distid}, {district}, bbid={bbid}, {hospital_name}.\")\n",
    "                    full_dataset.extend(data_vector)\n",
    "                    districtn = district \n",
    "                    hospital_namen = hospital_name\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to retrieve the page for distid={distid}, bbid={bbid}. Status code: {response.status_code}\")\n",
    "\n",
    "    # Print the full dataset\n",
    "    print(full_dataset)\n",
    "\n",
    "    # Assuming blood_bank_data_list is the list of dictionaries\n",
    "    dfx = pd.DataFrame(full_dataset)\n",
    "    # Print or display the DataFrame\n",
    "    print(dfx)\n",
    "\n",
    "    distid_bbid_list = dfx[[0, 1]].to_records(index=False).tolist()\n",
    "\n",
    "    # Print the list\n",
    "    print(distid_bbid_list)\n",
    "\n",
    "    # Specify the file path\n",
    "    csv_file_path = 'odisha_distid_bbid_list.csv'\n",
    "\n",
    "    # Write the list to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        # Create a CSV writer\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow(['distid', 'bbid'])\n",
    "        # Write the data\n",
    "        csv_writer.writerows(distid_bbid_list)\n",
    "        print(\"csv file written\")\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ead404e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T06:34:39.544462Z",
     "iopub.status.busy": "2024-04-11T06:34:39.544187Z",
     "iopub.status.idle": "2024-04-11T06:36:14.207258Z",
     "shell.execute_reply": "2024-04-11T06:36:14.205922Z"
    },
    "papermill": {
     "duration": 94.669792,
     "end_time": "2024-04-11T06:36:14.211186",
     "exception": false,
     "start_time": "2024-04-11T06:34:39.541394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 20), (1, 21), (1, 47), (2, 58), (3, 22), (3, 62), (4, 30), (5, 40), (5, 44), (6, 67), (7, 50), (7, 52), (8, 34), (9, 17), (9, 35), (9, 39), (10, 12), (10, 49), (10, 60), (10, 71), (10, 73), (10, 98), (11, 31), (11, 33), (11, 83), (11, 87), (12, 15), (12, 32), (12, 79), (13, 56), (14, 19), (14, 27), (14, 45), (15, 16), (16, 57), (17, 46), (18, 28), (19, 78), (20, 23), (20, 63), (20, 65), (20, 69), (22, 29), (22, 53), (23, 36), (23, 88), (23, 89), (23, 97), (24, 24), (25, 18), (25, 37), (25, 48), (25, 51), (26, 61), (27, 7), (27, 54), (28, 43), (29, 38), (30, 42), (30, 64), (31, 25)]\n",
      "Failed to retrieve the page for distid=1, bbid=20. Status code: 404\n",
      "Failed to retrieve the page for distid=1, bbid=21. Status code: 404\n",
      "Failed to retrieve the page for distid=1, bbid=47. Status code: 404\n",
      "Failed to retrieve the page for distid=2, bbid=58. Status code: 404\n",
      "Failed to retrieve the page for distid=3, bbid=22. Status code: 404\n",
      "Failed to retrieve the page for distid=3, bbid=62. Status code: 404\n",
      "Failed to retrieve the page for distid=4, bbid=30. Status code: 404\n",
      "Failed to retrieve the page for distid=5, bbid=40. Status code: 404\n",
      "Failed to retrieve the page for distid=5, bbid=44. Status code: 404\n",
      "Failed to retrieve the page for distid=6, bbid=67. Status code: 404\n",
      "Failed to retrieve the page for distid=7, bbid=50. Status code: 404\n",
      "Failed to retrieve the page for distid=7, bbid=52. Status code: 404\n",
      "Failed to retrieve the page for distid=8, bbid=34. Status code: 404\n",
      "Failed to retrieve the page for distid=9, bbid=17. Status code: 404\n",
      "Failed to retrieve the page for distid=9, bbid=35. Status code: 404\n",
      "Failed to retrieve the page for distid=9, bbid=39. Status code: 404\n",
      "Failed to retrieve the page for distid=10, bbid=12. Status code: 404\n",
      "Failed to retrieve the page for distid=10, bbid=49. Status code: 404\n",
      "Failed to retrieve the page for distid=10, bbid=60. Status code: 404\n",
      "Failed to retrieve the page for distid=10, bbid=71. Status code: 404\n",
      "Failed to retrieve the page for distid=10, bbid=73. Status code: 404\n",
      "Failed to retrieve the page for distid=10, bbid=98. Status code: 404\n",
      "Failed to retrieve the page for distid=11, bbid=31. Status code: 404\n",
      "Failed to retrieve the page for distid=11, bbid=33. Status code: 404\n",
      "Failed to retrieve the page for distid=11, bbid=83. Status code: 404\n",
      "Failed to retrieve the page for distid=11, bbid=87. Status code: 404\n",
      "Failed to retrieve the page for distid=12, bbid=15. Status code: 404\n",
      "Failed to retrieve the page for distid=12, bbid=32. Status code: 404\n",
      "Failed to retrieve the page for distid=12, bbid=79. Status code: 404\n",
      "Failed to retrieve the page for distid=13, bbid=56. Status code: 404\n",
      "Failed to retrieve the page for distid=14, bbid=19. Status code: 404\n",
      "Failed to retrieve the page for distid=14, bbid=27. Status code: 404\n",
      "Failed to retrieve the page for distid=14, bbid=45. Status code: 404\n",
      "Failed to retrieve the page for distid=15, bbid=16. Status code: 404\n",
      "Failed to retrieve the page for distid=16, bbid=57. Status code: 404\n",
      "Failed to retrieve the page for distid=17, bbid=46. Status code: 404\n",
      "Failed to retrieve the page for distid=18, bbid=28. Status code: 404\n",
      "Failed to retrieve the page for distid=19, bbid=78. Status code: 404\n",
      "Failed to retrieve the page for distid=20, bbid=23. Status code: 404\n",
      "Failed to retrieve the page for distid=20, bbid=63. Status code: 404\n",
      "Failed to retrieve the page for distid=20, bbid=65. Status code: 404\n",
      "Failed to retrieve the page for distid=20, bbid=69. Status code: 404\n",
      "Failed to retrieve the page for distid=22, bbid=29. Status code: 404\n",
      "Failed to retrieve the page for distid=22, bbid=53. Status code: 404\n",
      "Failed to retrieve the page for distid=23, bbid=36. Status code: 404\n",
      "Failed to retrieve the page for distid=23, bbid=88. Status code: 404\n",
      "Failed to retrieve the page for distid=23, bbid=89. Status code: 404\n",
      "Failed to retrieve the page for distid=23, bbid=97. Status code: 404\n",
      "Failed to retrieve the page for distid=24, bbid=24. Status code: 404\n",
      "Failed to retrieve the page for distid=25, bbid=18. Status code: 404\n",
      "Failed to retrieve the page for distid=25, bbid=37. Status code: 404\n",
      "Failed to retrieve the page for distid=25, bbid=48. Status code: 404\n",
      "Failed to retrieve the page for distid=25, bbid=51. Status code: 404\n",
      "Failed to retrieve the page for distid=26, bbid=61. Status code: 404\n",
      "Failed to retrieve the page for distid=27, bbid=7. Status code: 404\n",
      "Failed to retrieve the page for distid=27, bbid=54. Status code: 404\n",
      "Failed to retrieve the page for distid=28, bbid=43. Status code: 404\n",
      "Failed to retrieve the page for distid=29, bbid=38. Status code: 404\n",
      "Failed to retrieve the page for distid=30, bbid=42. Status code: 404\n",
      "Failed to retrieve the page for distid=30, bbid=64. Status code: 404\n",
      "Failed to retrieve the page for distid=31, bbid=25. Status code: 404\n",
      "[]\n",
      "csv file written\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'odisha_distid_bbid_list.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "ids = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert the DataFrame to a list of tuples\n",
    "distid_bbid_list = [tuple(x) for x in ids.to_numpy()]\n",
    "\n",
    "# Display the resulting list\n",
    "print(distid_bbid_list)\n",
    "\n",
    "\n",
    "# Data storage for the entire dataset\n",
    "full_dataset = []\n",
    "districtn = \"Test\"\n",
    "hospital_namen = \"Test\"\n",
    "\n",
    "district = \"Test\"\n",
    "hospital_name = \"Test\"\n",
    "\n",
    "# Iterate over all possible combinations of distid and bbid\n",
    "for distid, bbid in distid_bbid_list:\n",
    "    url = base_url.format(distid, bbid)\n",
    "\n",
    "    # Assuming it's a POST request; adjust if necessary\n",
    "    response = requests.post(url, headers=headers, verify=False)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Extract relevant information from the HTML\n",
    "        data_vector = []\n",
    "        rows = soup.find_all('tr')\n",
    "        for row in rows:\n",
    "            # Extract individual cells from the row\n",
    "            cells = row.find_all('td')\n",
    "\n",
    "            # Extract and organize data into a vector\n",
    "            district = cells[0].text.strip()\n",
    "            hospital_name = cells[1].text.strip()\n",
    "            blood_units = [cell.text.strip() for cell in cells[2:10]]\n",
    "            last_updated = cells[-2].text.strip()\n",
    "            \n",
    "            # Create a vector with the extracted data\n",
    "            row_vector = [distid, bbid, district, hospital_name] + blood_units + [last_updated]\n",
    "            \n",
    "        if district==districtn and hospital_name==hospital_namen:\n",
    "            pass\n",
    "        else:\n",
    "            # Append the vector to the data list\n",
    "            data_vector.append(row_vector)\n",
    "            \n",
    "            # Append the data vector to the full dataset\n",
    "            print(f\"Got data for distid={distid}, {district}, bbid={bbid}, {hospital_name}.\")\n",
    "            full_dataset.extend(data_vector)\n",
    "            districtn = district \n",
    "            hospital_namen = hospital_name\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page for distid={distid}, bbid={bbid}. Status code: {response.status_code}\")\n",
    "\n",
    "# Print the full dataset\n",
    "print(full_dataset)\n",
    "\n",
    "# Output as csv\n",
    "# Specify the file path\n",
    "\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create a file name using the formatted date\n",
    "file_name = f\"../../Data/India Blood Banks/Odisha_scraped/odisha_{current_date}.csv\"\n",
    "\n",
    "# Write the list to the CSV file\n",
    "with open(file_name, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header\n",
    "    csv_writer.writerow(['distid', 'bbid', 'district', 'hospital_name', 'A+', 'A-','B+','B-','AB+','AB-','O+','O-','Last updated'])\n",
    "\n",
    "    # Write the data\n",
    "    csv_writer.writerows(full_dataset)\n",
    "    print(\"csv file written\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 100.149875,
   "end_time": "2024-04-11T06:36:14.541857",
   "environment_variables": {},
   "exception": null,
   "input_path": "scrape_odisha.ipynb",
   "output_path": "scrape_odisha_done.ipynb",
   "parameters": {},
   "start_time": "2024-04-11T06:34:34.391982",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
